# Memexor

> Bring any data stream into your LLMâ€™s memory.

**Memexor** is an open-source ingestion and retrieval layer that makes it easy to feed **text, audio, video, or binary streams** into a **vector store**, and expose that content to your agent via the [Model Context Protocol (MCP)](https://smith.langchain.com/hub/openai/mcp-docs).

Inspired by Vannevar Bushâ€™s vision of the â€œMemexâ€â€”a device to augment human memoryâ€”**Memexor** is built to give your LLM agents a persistent, multimodal, searchable memory layer.

---

## âš¡ï¸ Why Memexor?

LLMs are powerfulâ€”but forgetful.

Memexor helps you:

- ğŸ™ Ingest **any stream**: audio, video, PDFs, binary logs, even EEG
- ğŸ§  Convert into embeddings and store in your **vector DB of choice**
- ğŸ” Expose a `/tools/search` endpoint via MCP for agent queries
- ğŸ§­ Build contextual, memory-enabled AI systems in minutes

---

## ğŸ”§ Quickstart (dev preview)

```bash
git clone https://github.com/yourname/memexor.git
cd memexor
cp .env.example .env
docker-compose up --build
```
Then:
```bash
curl -F 'file=@sample.txt' localhost:8000/upload/text
```
##ğŸ§± Architecture
```text
[ text/audio/video stream ]
          â†“
   [ Ingestion API (FastAPI) ]
          â†“
[ Embedding layer (OpenAI or local) ]
          â†“
[ Vector DB (Weaviate, Pinecone, etc.) ]
          â†“
[ MCP-compatible /tools/search endpoint ]
```

---

## ğŸ—º Roadmap

- [x] Text ingestion + OpenAI embedding
- [ ] Audio and video file ingestion
- [ ] Plug-ins for CLIP, Whisper, ImageBind
- [ ] Live stream support (RTSP/WebSocket)
- [ ] MCP server with hybrid search
- [ ] Hosted control plane (auth, RBAC, metrics)

---

## ğŸŒ Use Cases

- ğŸ§  Give your agent a memory of everything itâ€™s seen/heard
- ğŸ” Index and search your meeting recordings, notes, files
- ğŸ§ª Experiment with new modalities (EEG, IMU, sensors)
- ğŸ’¼ Build powerful internal tools with long-term knowledge

---

## ğŸ“¦ Tech Stack

- [FastAPI](https://fastapi.tiangolo.com/) for the ingestion server
- [Weaviate](https://weaviate.io/) for vector storage
- [OpenAI](https://platform.openai.com/docs) or BYO embedding model
- [Docker Compose](https://docs.docker.com/compose/) for local orchestration

---

## ğŸ¤ Contributing

Want to help build the open memory layer for multimodal AI agents?  
Open issues, file PRs, or join the conversation in [GitHub Discussions](https://github.com/yourname/memexor/discussions).

---

## ğŸ§¾ License

MIT (for now). We may introduce a dual-license or BSL model as Memexor evolves. All feedback welcome.

---

## ğŸ‘‹ Stay in touch

Follow [@yourhandle](https://twitter.com/yourhandle) or star the repo to stay in the loop.  
Weâ€™re in early validationâ€”your feedback can shape Memexorâ€™s future.
